{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07d3bf21af854aaa9665454add71ff30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7eaa2dcecded4fdb81c1818cea20973f",
              "IPY_MODEL_5328ae9d5f9c4ef59fae508b988e3896",
              "IPY_MODEL_971d1d995d5847518cce70c778c2671f"
            ],
            "layout": "IPY_MODEL_d8563bc0c46f43948ffb4148923e7c08"
          }
        },
        "7eaa2dcecded4fdb81c1818cea20973f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bca17d4c08a47eea0ba992d2643af31",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_56ecaaebe6af43eeab4869ccc83b40c5",
            "value": "Loadingâ€‡weights:â€‡100%"
          }
        },
        "5328ae9d5f9c4ef59fae508b988e3896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b7cc34d1abe4e30b30489a853a90b82",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7b7b97c64c04cf2a98d422f356a422c",
            "value": 103
          }
        },
        "971d1d995d5847518cce70c778c2671f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af6a68450dcc48189df3cab9854c5b2c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d5e8379a6151460c944082a3784b7c88",
            "value": "â€‡103/103â€‡[00:00&lt;00:00,â€‡488.13it/s,â€‡Materializingâ€‡param=pooler.dense.weight]"
          }
        },
        "d8563bc0c46f43948ffb4148923e7c08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bca17d4c08a47eea0ba992d2643af31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ecaaebe6af43eeab4869ccc83b40c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b7cc34d1abe4e30b30489a853a90b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b7b97c64c04cf2a98d422f356a422c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af6a68450dcc48189df3cab9854c5b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5e8379a6151460c944082a3784b7c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQqUqTvh-hv4",
        "outputId": "cb689ab4-319d-4c4b-fedc-f02237054250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2"
      ],
      "metadata": {
        "id": "BoDV49l2A0N6"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in reader.pages:\n",
        "            print(\"loop\")\n",
        "            text += page.extract_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "x3Nov96-A1by"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_data = extract_text_from_pdf(\"/content/Zubair-Naseer_Resume.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7sFmHItA4XW",
        "outputId": "2ca90efd-1246-41be-b259-749012050599"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "xGFCYGohBDhx",
        "outputId": "f75e90a2-a44b-4a88-fab1-8799c40d5f92"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Zubair Naseer  \\nPython Developer | AI & Automation Engineer  \\nðŸ“ Karachi , Pakistan  | ðŸ“ž +92 334 -2771431  | âœ‰ï¸ iamzubairnaseer@gmail.com  | ðŸŒ Portfolio  | LinkedIn  | GitHub  \\n \\nResults -driven Python Developer with hands -on experience in automation , web scraping , and generative AI \\nsystems . Skilled in Python (FastAPI, Pandas, Selenium) , LLM integration  with LangChain/DSPy , and vector \\ndatabases  such as Redis Stack. Experienced in building RAG pipelines , chatbots , and data automation workflows . \\nPassionate about designing scalable , produc tion -ready AI  and backend systems . \\n \\nPROFESSIONAL EXPERIENCE  \\nSoftware Engineer â€“ JS Bank  | Sept 2025 â€“ Present  \\n\\uf0b7 Developed Robotic Process Automation (RPA  workflows using Selenium  to streamline repetitive tasks.  \\n\\uf0b7 Integrated Large Language Models (LLMs)  for intelligent data extraction from documents.  \\n\\uf0b7 Automated Oracle -to-Excel  data pipelines, improving reporting speed and accuracy.  \\n\\uf0b7 Built FastAPI -based microservices  to streamline automated email communication.  \\n\\uf0b7 Implemented Elasticsearch logging  for proactive monitoring and error detection.  \\n\\uf0b7 Containerized applications using Docker  for scalable and consistent deployments . \\nAI Engineer â€“ IRVINEi  | July â€“ Sept 2025  \\n\\uf0b7 Built LLM -based conversational systems  and optimized smart -home classification workflow s using context \\nengineering . \\n\\uf0b7 Developed Redis -powered context memory  for AI agents . \\n\\uf0b7 Implemented local LLM inference pipelines (Ollama)  to minimize latency and cloud costs.  \\n\\uf0b7 Fine -tuned wake -word detection models  to achieve highly accurate voice activation.  \\nAI Intern â€“ IRVINEi  | May â€“ June 2025  \\n\\uf0b7 Developed RAG -based FAQ Agent  with Redis -stack vector database for intelligent document retrieval.  \\n\\uf0b7 Fine -tuned and optimized LLM performance  by minimizing prompt length and merging agent logic.  \\n\\uf0b7 Worked with DSPy  and LangGr aph  to build modular and composable LLM workflows.  \\n\\uf0b7 Collaborated with cross -functional teams to support research & deployment of production -grade AI systems . \\n \\nTECHNICAL SKILLS  \\n\\uf0b7 Languages : Python, JavaScript  \\n\\uf0b7 Frameworks & Tools: FastAPI, LangChain, DSPy, LangGraph, Selenium, Pandas , Matplotlib  \\n\\uf0b7 Databases :  Oracle , Redis Stack (Vector DB), MongoDB, Firebase  \\n\\uf0b7 AI/ML: Hugging Face, PyTorch, RAG Systems, Prompt Engineering, Model Fine -tuning  \\n\\uf0b7 DevOps:  Docker,  Git, REST APIs  \\n \\nKEY PROJECTS  \\n\\uf0b7 Social Media Performance Analysis : Analyzed synthetic social media data using time -series techniques and \\nvisual comparisons to identify top -performing platforms, content types, and posting days.  \\n\\uf0b7 RAG -based FAQ Agent (LLM + Vector DB)  â€“ Built a production -grade RAG pipeline using DSPy , FastAPI, \\nRedis Stack, and custom prompt workflows.  \\n\\uf0b7 Lane Centering for Autonomous Vehicles (F inal Year Project ) â€“ Developed a real -time lane detection \\nsystem for autonomous vehicles. The model, trained on real -world data, triggers alerts when the vehi cle drifts \\nnear or across lane dividers . \\n\\uf0b7 Traffic Sign Recognition (Python)  â€“ Trained a machine learning model to detect and classify traffic signs in \\nimages/videos for autonomous driving applications.  \\n \\nEDUCATION  \\nBachelor of Engineering in Computer & Information Systems  \\nNED University of Engineering and Technology, Karachi  | Nov 2017 â€“ Oct 2021  \\nCGPA:  3.76 / 4.00  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_2_data = extract_text_from_pdf(\"/content/Zubair_Naseer-Resume_.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjliBUKJBE_g",
        "outputId": "b18f6b8f-eb4a-4ee9-935d-298cb0037349"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loop\n",
            "loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_2_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "BEUsjJPbBhjm",
        "outputId": "27d19556-aa44-4a06-ab20-946cdd835b38"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\nZubair Naseer  \\n \\n      ðŸ“ Frere Town, Clifton, Karachi  ðŸ“§ iamzubairnaseer@gmail.com  ðŸ“ž +92 334-2771431  \\n \\nEducation  \\nNED University of Engineering and Technology  Karachi , PK \\nBachelor of Engineering Computer Systems                                                                                                             October 2021   \\nCGPA: 3.7 59 / 4.00  \\n \\nExperience\\n \\nJS Bank  \\nSoftware Engineer       Karachi , PK \\n          Sept 2025 â€“ Present  \\nâ— Design and implement Robotic Process Automation  (RPA) workflows with Selenium to optimize repetitive \\ninternal tasks.  \\nâ— Engineer automated data pipelines using Pandas  to transform raw Oracle  database records into business -\\ndefined structures for accurate reporting.  \\nâ— Integrated Large Language Models  (LLMs) for intelligent data extraction from documents . \\nâ— Develop and maintain FastAPI -based microservices  to automate enterprise email communication and streamline \\nbackend workflows.  \\n \\nIRVINEi                                                                                                                                                                 California, US â€“ Remote  \\nAI Engineer               July â€“ Sept  2025  \\n \\nâ— Built LLM -based conversational systems  and optimized smart -home classification workflows using \\ncontext engineering . \\nâ— Developed Redis -powered context memory systems  to maintain state for AI agents and reduce response latency . \\nâ— Implemented local LLM inference pipelines ( Ollama ) to minimize cloud infrastructure costs and data latency.  \\nâ— Fine-tuned wake -word detection models  to achieve highly accurate voice activation . \\n \\nIRVINEi                                                                                                                                                                 California, US â€“ Remote  \\nAI Inter n              May â€“ June 2025  \\n \\nâ— Developed RAG -based FAQ Agent  with Redis -stack vector database for intelligent document retrieval.  \\nâ— Reduced operational prompt costs by minimizing prompt length and merging agent logic without sacrificing \\naccuracy.  \\nâ— Worked with DSPy and LangGraph to build modular and composable LLM workflows.  \\nâ— Collaborated with cross -functional teams to support research & deployment of production -grade AI  systems.  \\n \\n          Technical  Projects  \\n \\nâ— Lane Centering for Autonomous Vehicles (Final Year Project)  â€“ Developed a real -time lane detection \\nsystem for autonomous vehicles. The model, trained on real -world data, triggers alerts when the \\nvehicle drifts near or across lane dividers.   \\nâ— Traffic Sign Recognition (Python)  â€“ Trained a machine learning model to det ect and classify traffic \\nsigns in images/videos for autonomous driving applications.  \\nâ— Social Media Performance Analysis  â€“ Analyzed synthetic social media data using time -series techniques and \\nvisual comparisons to identify top -performing platforms, content types, and posting days.  \\n \\nLeadership & Activities\\n \\nâ— QUEST -E-Techâ€™20 (ORIC) Web Development Contest 2020 â€“ Winner : Secured first place in a \\ncompetitive university -wide web development hackathon focused on functional system design . \\nâ— Developer Student Clubs (DSC) â€“ 5th Place  â€“ Webbed Wonders Workshop June 2020  \\n \\nTechnical Skills  \\n \\nPython, JavaScript, FastAPI, Django, LangChain, DSPy, Selenium, Pandas, Oracle, Redis Stack, MongoDB,  \\nDocker, Git.  \\n \\nCertification s\\n \\nâ— Python Programming â€“ Saylani MIT  \\nâ— Programming Essentials in Python â€“ Cisco Networking  Academy   \\nâ— Git & GitHub â€“ 365 DataScience  \\nâ— Frontend Fundamentals â€“ Priple.com  \\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjRT5lr0OfLY",
        "outputId": "652bfeca-15e1-4ded-e6be-f0f3b5996831"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "yL89vMY6Biw6"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilrPf8_gOoI1",
        "outputId": "8262642f-a6a4-47b7-e0d8-9a04bc29fea9"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lg-jD9eAOsL7",
        "outputId": "bc160ba0-627c-4df3-edea-ba57be2ceb32"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " \"he's\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " \"i've\",\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " \"we've\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = re.sub(r'[^a-zA-Z ]', '', cv_data)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "collapsed": true,
        "id": "wLfPpZaJ4wTt",
        "outputId": "e9330b35-2f7e-4263-c1ae-291032db95d9"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Zubair Naseer  Python Developer  AI  Automation Engineer   Karachi  Pakistan          iamzubairnaseergmailcom    Portfolio   LinkedIn   GitHub   Results driven Python Developer with hands on experience in automation  web scraping  and generative AI systems  Skilled in Python FastAPI Pandas Selenium  LLM integration  with LangChainDSPy  and vector databases  such as Redis Stack Experienced in building RAG pipelines  chatbots  and data automation workflows  Passionate about designing scalable  produc tion ready AI  and backend systems   PROFESSIONAL EXPERIENCE  Software Engineer  JS Bank   Sept   Present   Developed Robotic Process Automation RPA  workflows using Selenium  to streamline repetitive tasks   Integrated Large Language Models LLMs  for intelligent data extraction from documents   Automated Oracle toExcel  data pipelines improving reporting speed and accuracy   Built FastAPI based microservices  to streamline automated email communication   Implemented Elasticsearch logging  for proactive monitoring and error detection   Containerized applications using Docker  for scalable and consistent deployments  AI Engineer  IRVINEi   July  Sept    Built LLM based conversational systems  and optimized smart home classification workflow s using context engineering   Developed Redis powered context memory  for AI agents   Implemented local LLM inference pipelines Ollama  to minimize latency and cloud costs   Fine tuned wake word detection models  to achieve highly accurate voice activation  AI Intern  IRVINEi   May  June    Developed RAG based FAQ Agent  with Redis stack vector database for intelligent document retrieval   Fine tuned and optimized LLM performance  by minimizing prompt length and merging agent logic   Worked with DSPy  and LangGr aph  to build modular and composable LLM workflows   Collaborated with cross functional teams to support research  deployment of production grade AI systems   TECHNICAL SKILLS   Languages  Python JavaScript   Frameworks  Tools FastAPI LangChain DSPy LangGraph Selenium Pandas  Matplotlib   Databases   Oracle  Redis Stack Vector DB MongoDB Firebase   AIML Hugging Face PyTorch RAG Systems Prompt Engineering Model Fine tuning   DevOps  Docker  Git REST APIs   KEY PROJECTS   Social Media Performance Analysis  Analyzed synthetic social media data using time series techniques and visual comparisons to identify top performing platforms content types and posting days   RAG based FAQ Agent LLM  Vector DB   Built a production grade RAG pipeline using DSPy  FastAPI Redis Stack and custom prompt workflows   Lane Centering for Autonomous Vehicles F inal Year Project   Developed a real time lane detection system for autonomous vehicles The model trained on real world data triggers alerts when the vehi cle drifts near or across lane dividers   Traffic Sign Recognition Python   Trained a machine learning model to detect and classify traffic signs in imagesvideos for autonomous driving applications   EDUCATION  Bachelor of Engineering in Computer  Information Systems  NED University of Engineering and Technology Karachi   Nov   Oct   CGPA      '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split()\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d4r_-dnqNdGT",
        "outputId": "55ba0d9b-d7dc-4dc4-fb9b-0984089ecca8"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Zubair',\n",
              " 'Naseer',\n",
              " 'Python',\n",
              " 'Developer',\n",
              " 'AI',\n",
              " 'Automation',\n",
              " 'Engineer',\n",
              " 'Karachi',\n",
              " 'Pakistan',\n",
              " 'iamzubairnaseergmailcom',\n",
              " 'Portfolio',\n",
              " 'LinkedIn',\n",
              " 'GitHub',\n",
              " 'Results',\n",
              " 'driven',\n",
              " 'Python',\n",
              " 'Developer',\n",
              " 'with',\n",
              " 'hands',\n",
              " 'on',\n",
              " 'experience',\n",
              " 'in',\n",
              " 'automation',\n",
              " 'web',\n",
              " 'scraping',\n",
              " 'and',\n",
              " 'generative',\n",
              " 'AI',\n",
              " 'systems',\n",
              " 'Skilled',\n",
              " 'in',\n",
              " 'Python',\n",
              " 'FastAPI',\n",
              " 'Pandas',\n",
              " 'Selenium',\n",
              " 'LLM',\n",
              " 'integration',\n",
              " 'with',\n",
              " 'LangChainDSPy',\n",
              " 'and',\n",
              " 'vector',\n",
              " 'databases',\n",
              " 'such',\n",
              " 'as',\n",
              " 'Redis',\n",
              " 'Stack',\n",
              " 'Experienced',\n",
              " 'in',\n",
              " 'building',\n",
              " 'RAG',\n",
              " 'pipelines',\n",
              " 'chatbots',\n",
              " 'and',\n",
              " 'data',\n",
              " 'automation',\n",
              " 'workflows',\n",
              " 'Passionate',\n",
              " 'about',\n",
              " 'designing',\n",
              " 'scalable',\n",
              " 'produc',\n",
              " 'tion',\n",
              " 'ready',\n",
              " 'AI',\n",
              " 'and',\n",
              " 'backend',\n",
              " 'systems',\n",
              " 'PROFESSIONAL',\n",
              " 'EXPERIENCE',\n",
              " 'Software',\n",
              " 'Engineer',\n",
              " 'JS',\n",
              " 'Bank',\n",
              " 'Sept',\n",
              " 'Present',\n",
              " 'Developed',\n",
              " 'Robotic',\n",
              " 'Process',\n",
              " 'Automation',\n",
              " 'RPA',\n",
              " 'workflows',\n",
              " 'using',\n",
              " 'Selenium',\n",
              " 'to',\n",
              " 'streamline',\n",
              " 'repetitive',\n",
              " 'tasks',\n",
              " 'Integrated',\n",
              " 'Large',\n",
              " 'Language',\n",
              " 'Models',\n",
              " 'LLMs',\n",
              " 'for',\n",
              " 'intelligent',\n",
              " 'data',\n",
              " 'extraction',\n",
              " 'from',\n",
              " 'documents',\n",
              " 'Automated',\n",
              " 'Oracle',\n",
              " 'toExcel',\n",
              " 'data',\n",
              " 'pipelines',\n",
              " 'improving',\n",
              " 'reporting',\n",
              " 'speed',\n",
              " 'and',\n",
              " 'accuracy',\n",
              " 'Built',\n",
              " 'FastAPI',\n",
              " 'based',\n",
              " 'microservices',\n",
              " 'to',\n",
              " 'streamline',\n",
              " 'automated',\n",
              " 'email',\n",
              " 'communication',\n",
              " 'Implemented',\n",
              " 'Elasticsearch',\n",
              " 'logging',\n",
              " 'for',\n",
              " 'proactive',\n",
              " 'monitoring',\n",
              " 'and',\n",
              " 'error',\n",
              " 'detection',\n",
              " 'Containerized',\n",
              " 'applications',\n",
              " 'using',\n",
              " 'Docker',\n",
              " 'for',\n",
              " 'scalable',\n",
              " 'and',\n",
              " 'consistent',\n",
              " 'deployments',\n",
              " 'AI',\n",
              " 'Engineer',\n",
              " 'IRVINEi',\n",
              " 'July',\n",
              " 'Sept',\n",
              " 'Built',\n",
              " 'LLM',\n",
              " 'based',\n",
              " 'conversational',\n",
              " 'systems',\n",
              " 'and',\n",
              " 'optimized',\n",
              " 'smart',\n",
              " 'home',\n",
              " 'classification',\n",
              " 'workflow',\n",
              " 's',\n",
              " 'using',\n",
              " 'context',\n",
              " 'engineering',\n",
              " 'Developed',\n",
              " 'Redis',\n",
              " 'powered',\n",
              " 'context',\n",
              " 'memory',\n",
              " 'for',\n",
              " 'AI',\n",
              " 'agents',\n",
              " 'Implemented',\n",
              " 'local',\n",
              " 'LLM',\n",
              " 'inference',\n",
              " 'pipelines',\n",
              " 'Ollama',\n",
              " 'to',\n",
              " 'minimize',\n",
              " 'latency',\n",
              " 'and',\n",
              " 'cloud',\n",
              " 'costs',\n",
              " 'Fine',\n",
              " 'tuned',\n",
              " 'wake',\n",
              " 'word',\n",
              " 'detection',\n",
              " 'models',\n",
              " 'to',\n",
              " 'achieve',\n",
              " 'highly',\n",
              " 'accurate',\n",
              " 'voice',\n",
              " 'activation',\n",
              " 'AI',\n",
              " 'Intern',\n",
              " 'IRVINEi',\n",
              " 'May',\n",
              " 'June',\n",
              " 'Developed',\n",
              " 'RAG',\n",
              " 'based',\n",
              " 'FAQ',\n",
              " 'Agent',\n",
              " 'with',\n",
              " 'Redis',\n",
              " 'stack',\n",
              " 'vector',\n",
              " 'database',\n",
              " 'for',\n",
              " 'intelligent',\n",
              " 'document',\n",
              " 'retrieval',\n",
              " 'Fine',\n",
              " 'tuned',\n",
              " 'and',\n",
              " 'optimized',\n",
              " 'LLM',\n",
              " 'performance',\n",
              " 'by',\n",
              " 'minimizing',\n",
              " 'prompt',\n",
              " 'length',\n",
              " 'and',\n",
              " 'merging',\n",
              " 'agent',\n",
              " 'logic',\n",
              " 'Worked',\n",
              " 'with',\n",
              " 'DSPy',\n",
              " 'and',\n",
              " 'LangGr',\n",
              " 'aph',\n",
              " 'to',\n",
              " 'build',\n",
              " 'modular',\n",
              " 'and',\n",
              " 'composable',\n",
              " 'LLM',\n",
              " 'workflows',\n",
              " 'Collaborated',\n",
              " 'with',\n",
              " 'cross',\n",
              " 'functional',\n",
              " 'teams',\n",
              " 'to',\n",
              " 'support',\n",
              " 'research',\n",
              " 'deployment',\n",
              " 'of',\n",
              " 'production',\n",
              " 'grade',\n",
              " 'AI',\n",
              " 'systems',\n",
              " 'TECHNICAL',\n",
              " 'SKILLS',\n",
              " 'Languages',\n",
              " 'Python',\n",
              " 'JavaScript',\n",
              " 'Frameworks',\n",
              " 'Tools',\n",
              " 'FastAPI',\n",
              " 'LangChain',\n",
              " 'DSPy',\n",
              " 'LangGraph',\n",
              " 'Selenium',\n",
              " 'Pandas',\n",
              " 'Matplotlib',\n",
              " 'Databases',\n",
              " 'Oracle',\n",
              " 'Redis',\n",
              " 'Stack',\n",
              " 'Vector',\n",
              " 'DB',\n",
              " 'MongoDB',\n",
              " 'Firebase',\n",
              " 'AIML',\n",
              " 'Hugging',\n",
              " 'Face',\n",
              " 'PyTorch',\n",
              " 'RAG',\n",
              " 'Systems',\n",
              " 'Prompt',\n",
              " 'Engineering',\n",
              " 'Model',\n",
              " 'Fine',\n",
              " 'tuning',\n",
              " 'DevOps',\n",
              " 'Docker',\n",
              " 'Git',\n",
              " 'REST',\n",
              " 'APIs',\n",
              " 'KEY',\n",
              " 'PROJECTS',\n",
              " 'Social',\n",
              " 'Media',\n",
              " 'Performance',\n",
              " 'Analysis',\n",
              " 'Analyzed',\n",
              " 'synthetic',\n",
              " 'social',\n",
              " 'media',\n",
              " 'data',\n",
              " 'using',\n",
              " 'time',\n",
              " 'series',\n",
              " 'techniques',\n",
              " 'and',\n",
              " 'visual',\n",
              " 'comparisons',\n",
              " 'to',\n",
              " 'identify',\n",
              " 'top',\n",
              " 'performing',\n",
              " 'platforms',\n",
              " 'content',\n",
              " 'types',\n",
              " 'and',\n",
              " 'posting',\n",
              " 'days',\n",
              " 'RAG',\n",
              " 'based',\n",
              " 'FAQ',\n",
              " 'Agent',\n",
              " 'LLM',\n",
              " 'Vector',\n",
              " 'DB',\n",
              " 'Built',\n",
              " 'a',\n",
              " 'production',\n",
              " 'grade',\n",
              " 'RAG',\n",
              " 'pipeline',\n",
              " 'using',\n",
              " 'DSPy',\n",
              " 'FastAPI',\n",
              " 'Redis',\n",
              " 'Stack',\n",
              " 'and',\n",
              " 'custom',\n",
              " 'prompt',\n",
              " 'workflows',\n",
              " 'Lane',\n",
              " 'Centering',\n",
              " 'for',\n",
              " 'Autonomous',\n",
              " 'Vehicles',\n",
              " 'F',\n",
              " 'inal',\n",
              " 'Year',\n",
              " 'Project',\n",
              " 'Developed',\n",
              " 'a',\n",
              " 'real',\n",
              " 'time',\n",
              " 'lane',\n",
              " 'detection',\n",
              " 'system',\n",
              " 'for',\n",
              " 'autonomous',\n",
              " 'vehicles',\n",
              " 'The',\n",
              " 'model',\n",
              " 'trained',\n",
              " 'on',\n",
              " 'real',\n",
              " 'world',\n",
              " 'data',\n",
              " 'triggers',\n",
              " 'alerts',\n",
              " 'when',\n",
              " 'the',\n",
              " 'vehi',\n",
              " 'cle',\n",
              " 'drifts',\n",
              " 'near',\n",
              " 'or',\n",
              " 'across',\n",
              " 'lane',\n",
              " 'dividers',\n",
              " 'Traffic',\n",
              " 'Sign',\n",
              " 'Recognition',\n",
              " 'Python',\n",
              " 'Trained',\n",
              " 'a',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'model',\n",
              " 'to',\n",
              " 'detect',\n",
              " 'and',\n",
              " 'classify',\n",
              " 'traffic',\n",
              " 'signs',\n",
              " 'in',\n",
              " 'imagesvideos',\n",
              " 'for',\n",
              " 'autonomous',\n",
              " 'driving',\n",
              " 'applications',\n",
              " 'EDUCATION',\n",
              " 'Bachelor',\n",
              " 'of',\n",
              " 'Engineering',\n",
              " 'in',\n",
              " 'Computer',\n",
              " 'Information',\n",
              " 'Systems',\n",
              " 'NED',\n",
              " 'University',\n",
              " 'of',\n",
              " 'Engineering',\n",
              " 'and',\n",
              " 'Technology',\n",
              " 'Karachi',\n",
              " 'Nov',\n",
              " 'Oct',\n",
              " 'CGPA']"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "j2E4fKgvOvBg"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_clean = clean_text(cv_data)"
      ],
      "metadata": {
        "id": "8BqNBmpGPO5R"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "C6OLAJYIPPUy",
        "outputId": "23d5260c-7570-4f03-d3b8-00cea0673106"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'zubair naseer python developer ai automation engineer karachi pakistan iamzubairnaseergmailcom portfolio linkedin github results driven python developer hands experience automation web scraping generative ai systems skilled python fastapi pandas selenium llm integration langchaindspy vector databases redis stack experienced building rag pipelines chatbots data automation workflows passionate designing scalable produc tion ready ai backend systems professional experience software engineer js bank sept present developed robotic process automation rpa workflows using selenium streamline repetitive tasks integrated large language models llms intelligent data extraction documents automated oracle toexcel data pipelines improving reporting speed accuracy built fastapi based microservices streamline automated email communication implemented elasticsearch logging proactive monitoring error detection containerized applications using docker scalable consistent deployments ai engineer irvinei july sept built llm based conversational systems optimized smart home classification workflow using context engineering developed redis powered context memory ai agents implemented local llm inference pipelines ollama minimize latency cloud costs fine tuned wake word detection models achieve highly accurate voice activation ai intern irvinei may june developed rag based faq agent redis stack vector database intelligent document retrieval fine tuned optimized llm performance minimizing prompt length merging agent logic worked dspy langgr aph build modular composable llm workflows collaborated cross functional teams support research deployment production grade ai systems technical skills languages python javascript frameworks tools fastapi langchain dspy langgraph selenium pandas matplotlib databases oracle redis stack vector db mongodb firebase aiml hugging face pytorch rag systems prompt engineering model fine tuning devops docker git rest apis key projects social media performance analysis analyzed synthetic social media data using time series techniques visual comparisons identify top performing platforms content types posting days rag based faq agent llm vector db built production grade rag pipeline using dspy fastapi redis stack custom prompt workflows lane centering autonomous vehicles f inal year project developed real time lane detection system autonomous vehicles model trained real world data triggers alerts vehi cle drifts near across lane dividers traffic sign recognition python trained machine learning model detect classify traffic signs imagesvideos autonomous driving applications education bachelor engineering computer information systems ned university engineering technology karachi nov oct cgpa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_2_clean = clean_text(cv_2_data)"
      ],
      "metadata": {
        "id": "2CUtWiFDO48Q"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_2_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "7DDTP8RyPA-B",
        "outputId": "6b4b38c3-4750-4cf8-c56a-cbc3a3544645"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'zubair naseer frere town clifton karachi iamzubairnaseergmailcom education ned university engineering technology karachi pk bachelor engineering computer systems october cgpa experience js bank software engineer karachi pk sept present design implement robotic process automation rpa workflows selenium optimize repetitive internal tasks engineer automated data pipelines using pandas transform raw oracle database records business defined structures accurate reporting integrated large language models llms intelligent data extraction documents develop maintain fastapi based microservices automate enterprise email communication streamline backend workflows irvinei california us remote ai engineer july sept built llm based conversational systems optimized smart home classification workflows using context engineering developed redis powered context memory systems maintain state ai agents reduce response latency implemented local llm inference pipelines ollama minimize cloud infrastructure costs data latency finetuned wake word detection models achieve highly accurate voice activation irvinei california us remote ai inter n may june developed rag based faq agent redis stack vector database intelligent document retrieval reduced operational prompt costs minimizing prompt length merging agent logic without sacrificing accuracy worked dspy langgraph build modular composable llm workflows collaborated cross functional teams support research deployment production grade ai systems technical projects lane centering autonomous vehicles final year project developed real time lane detection system autonomous vehicles model trained real world data triggers alerts vehicle drifts near across lane dividers traffic sign recognition python trained machine learning model det ect classify traffic signs imagesvideos autonomous driving applications social media performance analysis analyzed synthetic social media data using time series techniques visual comparisons identify top performing platforms content types posting days leadership activities quest etech oric web development contest winner secured first place competitive university wide web development hackathon focused functional system design developer student clubs dsc th place webbed wonders workshop june technical skills python javascript fastapi django langchain dspy selenium pandas oracle redis stack mongodb docker git certification python programming saylani mit programming essentials python cisco networking academy git github datascience frontend fundamentals priplecom'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKujUFqNPCr6",
        "outputId": "d01eec92-0177-453a-94fc-46e3a279b0b2"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (26.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "NEyOXzyrQj_I"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "nIW4JBj3Qum0"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(cv_clean)"
      ],
      "metadata": {
        "id": "490dhe64Qwng"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfCe6TE3Q414",
        "outputId": "a72cf053-f643-46c3-e29e-3bac07cfad04"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "zubair naseer python developer ai automation engineer karachi pakistan iamzubairnaseergmailcom portfolio linkedin github results driven python developer hands experience automation web scraping generative ai systems skilled python fastapi pandas selenium llm integration langchaindspy vector databases redis stack experienced building rag pipelines chatbots data automation workflows passionate designing scalable produc tion ready ai backend systems professional experience software engineer js bank sept present developed robotic process automation rpa workflows using selenium streamline repetitive tasks integrated large language models llms intelligent data extraction documents automated oracle toexcel data pipelines improving reporting speed accuracy built fastapi based microservices streamline automated email communication implemented elasticsearch logging proactive monitoring error detection containerized applications using docker scalable consistent deployments ai engineer irvinei july sept built llm based conversational systems optimized smart home classification workflow using context engineering developed redis powered context memory ai agents implemented local llm inference pipelines ollama minimize latency cloud costs fine tuned wake word detection models achieve highly accurate voice activation ai intern irvinei may june developed rag based faq agent redis stack vector database intelligent document retrieval fine tuned optimized llm performance minimizing prompt length merging agent logic worked dspy langgr aph build modular composable llm workflows collaborated cross functional teams support research deployment production grade ai systems technical skills languages python javascript frameworks tools fastapi langchain dspy langgraph selenium pandas matplotlib databases oracle redis stack vector db mongodb firebase aiml hugging face pytorch rag systems prompt engineering model fine tuning devops docker git rest apis key projects social media performance analysis analyzed synthetic social media data using time series techniques visual comparisons identify top performing platforms content types posting days rag based faq agent llm vector db built production grade rag pipeline using dspy fastapi redis stack custom prompt workflows lane centering autonomous vehicles f inal year project developed real time lane detection system autonomous vehicles model trained real world data triggers alerts vehi cle drifts near across lane dividers traffic sign recognition python trained machine learning model detect classify traffic signs imagesvideos autonomous driving applications education bachelor engineering computer information systems ned university engineering technology karachi nov oct cgpa"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SKILLS = ['python', 'machine learning', 'deep learning', 'sql', 'llm', 'rpa','nlp', 'data analysis', 'tensorflow', 'pytorch', 'vector database']"
      ],
      "metadata": {
        "id": "P1xw73MuQ5nA"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_skills(text):\n",
        "    doc = nlp(text)\n",
        "    extracted_skills = set()\n",
        "    for token in doc:\n",
        "        if token.text.lower() in SKILLS:\n",
        "            extracted_skills.add(token.text)\n",
        "    return list(extracted_skills)"
      ],
      "metadata": {
        "id": "eTydX3EtRFEZ"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matched_skills = extract_skills(cv_clean)"
      ],
      "metadata": {
        "id": "FkZJ4u-8RJvE"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matched_skills"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05tzflghRcLY",
        "outputId": "7a574518-5cc0-416b-959b-559825ef5e74"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['llm', 'pytorch', 'rpa', 'python']"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matched_percentage = (len(matched_skills)/len(SKILLS)) * 100\n",
        "print(f\"{len(matched_skills)}/{len(SKILLS)} = {matched_percentage}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRycxZZo2pKu",
        "outputId": "f1dd15a5-1102-4e31-b3a4-497bafce2c80"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/11 = 36.36363636363637%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matched_skills = extract_skills(cv_2_clean)\n",
        "matched_skills"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqBk3SZm1g3v",
        "outputId": "ee63c8a5-fce6-4326-f5ae-5c5eb9a36907"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['llm', 'python', 'rpa']"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matched_percentage = (len(matched_skills)/len(SKILLS)) * 100\n",
        "print(f\"{matched_percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sFxCFQi24R_",
        "outputId": "38ab7bf1-b4b0-40a5-f93b-2bf476988c1a"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "sCY67xO4Rdei"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jd_text = \"\"\"ð—¥ð—²ð˜€ð—½ð—¼ð—»ð˜€ð—¶ð—¯ð—¶ð—¹ð—¶ð˜ð—¶ð—²ð˜€\n",
        "* Support the team in experimenting with AI and GenAI features\n",
        "* prepare and organize data for AI-related tasks\n",
        "* Assist in testing AI outputs and understanding model behavior\n",
        "* Work with LLM tools or APIs at a basic level (prompting, testing responses)\n",
        "* Support simple backend or data-related tasks\n",
        "* Conduct research on emerging AI technologies and methodologies.\n",
        "* Support the testing and validation of AI systems.\n",
        "\n",
        "ð—¥ð—²ð—¾ð˜‚ð—¶ð—¿ð—²ð—ºð—²ð—»ð˜ð˜€\n",
        "* Basic understanding of what AI, LLMs, and Generative AI are\n",
        "* Familiarity with Python at a beginner level\n",
        "* Awareness of databases (e.g., MongoDB or PostgreSQL, basic idea of how data is stored and used)\n",
        "* Understanding of basic technical concepts (APIs, JSON, data flow)\n",
        "* Willingness to learn, experiment, and ask questions\n",
        "* Ability to work collaboratively in a team-oriented environment.\n",
        "* Strong analytical and problem-solving skills.\"\"\""
      ],
      "metadata": {
        "id": "wSFrOq_ibjDe"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform([cv_clean, jd_text])"
      ],
      "metadata": {
        "id": "6QgnIJOybe-y"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8Nac8wUcU9d",
        "outputId": "3de8c1eb-d22c-426d-873c-ddc6f4fab24d"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
              "\twith 314 stored elements and shape (2, 296)>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt584ej-iRLl",
        "outputId": "8264b163-ece2-47e1-a1d7-b0e5ac19c0f0"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'zubair': 293, 'naseer': 171, 'python': 209, 'developer': 70, 'ai': 8, 'automation': 23, 'engineer': 84, 'karachi': 135, 'pakistan': 185, 'iamzubairnaseergmailcom': 114, 'portfolio': 193, 'linkedin': 150, 'github': 107, 'results': 223, 'driven': 77, 'hands': 109, 'experience': 88, 'web': 282, 'scraping': 228, 'generative': 105, 'systems': 249, 'skilled': 235, 'fastapi': 96, 'pandas': 186, 'selenium': 229, 'llm': 151, 'integration': 125, 'langchaindspy': 139, 'vector': 276, 'databases': 61, 'redis': 216, 'stack': 242, 'experienced': 89, 'building': 34, 'rag': 212, 'pipelines': 191, 'chatbots': 38, 'data': 59, 'workflows': 290, 'passionate': 187, 'designing': 66, 'scalable': 227, 'produc': 202, 'tion': 260, 'ready': 213, 'backend': 27, 'professional': 204, 'software': 239, 'js': 131, 'bank': 28, 'sept': 230, 'present': 198, 'developed': 69, 'robotic': 225, 'process': 201, 'rpa': 226, 'using': 274, 'streamline': 244, 'repetitive': 218, 'tasks': 250, 'integrated': 124, 'large': 144, 'language': 142, 'models': 167, 'llms': 152, 'intelligent': 126, 'extraction': 92, 'documents': 75, 'automated': 22, 'oracle': 181, 'toexcel': 262, 'improving': 119, 'reporting': 219, 'speed': 241, 'accuracy': 1, 'built': 35, 'based': 29, 'microservices': 163, 'email': 82, 'communication': 45, 'implemented': 118, 'elasticsearch': 81, 'logging': 154, 'proactive': 199, 'monitoring': 170, 'error': 87, 'detection': 68, 'containerized': 52, 'applications': 17, 'docker': 73, 'consistent': 51, 'deployments': 65, 'irvinei': 128, 'july': 133, 'conversational': 55, 'optimized': 179, 'smart': 237, 'home': 111, 'classification': 39, 'workflow': 289, 'context': 54, 'engineering': 85, 'powered': 196, 'memory': 160, 'agents': 7, 'local': 153, 'inference': 122, 'ollama': 177, 'minimize': 164, 'latency': 145, 'cloud': 42, 'costs': 56, 'fine': 98, 'tuned': 268, 'wake': 281, 'word': 286, 'achieve': 3, 'highly': 110, 'accurate': 2, 'voice': 280, 'activation': 5, 'intern': 127, 'may': 158, 'june': 134, 'faq': 95, 'agent': 6, 'database': 60, 'document': 74, 'retrieval': 224, 'performance': 188, 'minimizing': 165, 'prompt': 207, 'length': 148, 'merging': 161, 'logic': 155, 'worked': 288, 'dspy': 79, 'langgr': 140, 'aph': 15, 'build': 33, 'modular': 168, 'composable': 47, 'collaborated': 43, 'cross': 57, 'functional': 103, 'teams': 252, 'support': 246, 'research': 220, 'deployment': 64, 'production': 203, 'grade': 108, 'technical': 253, 'skills': 236, 'languages': 143, 'javascript': 130, 'frameworks': 102, 'tools': 263, 'langchain': 138, 'langgraph': 141, 'matplotlib': 157, 'db': 63, 'mongodb': 169, 'firebase': 99, 'aiml': 9, 'hugging': 113, 'face': 93, 'pytorch': 210, 'model': 166, 'tuning': 269, 'devops': 71, 'git': 106, 'rest': 222, 'apis': 16, 'key': 136, 'projects': 206, 'social': 238, 'media': 159, 'analysis': 11, 'analyzed': 13, 'synthetic': 247, 'time': 259, 'series': 231, 'techniques': 254, 'visual': 279, 'comparisons': 46, 'identify': 116, 'top': 264, 'performing': 189, 'platforms': 192, 'content': 53, 'types': 270, 'posting': 195, 'days': 62, 'pipeline': 190, 'custom': 58, 'lane': 137, 'centering': 36, 'autonomous': 24, 'vehicles': 278, 'inal': 121, 'year': 292, 'project': 205, 'real': 214, 'system': 248, 'trained': 266, 'world': 291, 'triggers': 267, 'alerts': 10, 'vehi': 277, 'cle': 41, 'drifts': 76, 'near': 172, 'across': 4, 'dividers': 72, 'traffic': 265, 'sign': 232, 'recognition': 215, 'machine': 156, 'learning': 147, 'detect': 67, 'classify': 40, 'signs': 233, 'imagesvideos': 117, 'driving': 78, 'education': 80, 'bachelor': 26, 'computer': 48, 'information': 123, 'ned': 173, 'university': 272, 'technology': 256, 'nov': 174, 'oct': 175, 'cgpa': 37, 'ð—¥ð—²ð˜€ð—½ð—¼ð—»ð˜€ð—¶ð—¯ð—¶ð—¹ð—¶ð˜ð—¶ð—²ð˜€': 295, 'the': 258, 'team': 251, 'in': 120, 'experimenting': 91, 'with': 285, 'and': 14, 'genai': 104, 'features': 97, 'prepare': 197, 'organize': 182, 'for': 101, 'related': 217, 'assist': 20, 'testing': 257, 'outputs': 184, 'understanding': 271, 'behavior': 32, 'work': 287, 'or': 180, 'at': 21, 'basic': 30, 'level': 149, 'prompting': 208, 'responses': 221, 'simple': 234, 'conduct': 50, 'on': 178, 'emerging': 83, 'technologies': 255, 'methodologies': 162, 'validation': 275, 'of': 176, 'ð—¥ð—²ð—¾ð˜‚ð—¶ð—¿ð—²ð—ºð—²ð—»ð˜ð˜€': 294, 'what': 283, 'are': 18, 'familiarity': 94, 'beginner': 31, 'awareness': 25, 'postgresql': 194, 'idea': 115, 'how': 112, 'is': 129, 'stored': 243, 'used': 273, 'concepts': 49, 'json': 132, 'flow': 100, 'willingness': 284, 'to': 261, 'learn': 146, 'experiment': 90, 'ask': 19, 'questions': 211, 'ability': 0, 'collaboratively': 44, 'oriented': 183, 'environment': 86, 'strong': 245, 'analytical': 12, 'problem': 200, 'solving': 240}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "15ZzMtufitDK",
        "outputId": "98da2001-f190-4950-9062-347762917d0c"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ability', 'accuracy', 'accurate', 'achieve', 'across',\n",
              "       'activation', 'agent', 'agents', 'ai', 'aiml', 'alerts',\n",
              "       'analysis', 'analytical', 'analyzed', 'and', 'aph', 'apis',\n",
              "       'applications', 'are', 'ask', 'assist', 'at', 'automated',\n",
              "       'automation', 'autonomous', 'awareness', 'bachelor', 'backend',\n",
              "       'bank', 'based', 'basic', 'beginner', 'behavior', 'build',\n",
              "       'building', 'built', 'centering', 'cgpa', 'chatbots',\n",
              "       'classification', 'classify', 'cle', 'cloud', 'collaborated',\n",
              "       'collaboratively', 'communication', 'comparisons', 'composable',\n",
              "       'computer', 'concepts', 'conduct', 'consistent', 'containerized',\n",
              "       'content', 'context', 'conversational', 'costs', 'cross', 'custom',\n",
              "       'data', 'database', 'databases', 'days', 'db', 'deployment',\n",
              "       'deployments', 'designing', 'detect', 'detection', 'developed',\n",
              "       'developer', 'devops', 'dividers', 'docker', 'document',\n",
              "       'documents', 'drifts', 'driven', 'driving', 'dspy', 'education',\n",
              "       'elasticsearch', 'email', 'emerging', 'engineer', 'engineering',\n",
              "       'environment', 'error', 'experience', 'experienced', 'experiment',\n",
              "       'experimenting', 'extraction', 'face', 'familiarity', 'faq',\n",
              "       'fastapi', 'features', 'fine', 'firebase', 'flow', 'for',\n",
              "       'frameworks', 'functional', 'genai', 'generative', 'git', 'github',\n",
              "       'grade', 'hands', 'highly', 'home', 'how', 'hugging',\n",
              "       'iamzubairnaseergmailcom', 'idea', 'identify', 'imagesvideos',\n",
              "       'implemented', 'improving', 'in', 'inal', 'inference',\n",
              "       'information', 'integrated', 'integration', 'intelligent',\n",
              "       'intern', 'irvinei', 'is', 'javascript', 'js', 'json', 'july',\n",
              "       'june', 'karachi', 'key', 'lane', 'langchain', 'langchaindspy',\n",
              "       'langgr', 'langgraph', 'language', 'languages', 'large', 'latency',\n",
              "       'learn', 'learning', 'length', 'level', 'linkedin', 'llm', 'llms',\n",
              "       'local', 'logging', 'logic', 'machine', 'matplotlib', 'may',\n",
              "       'media', 'memory', 'merging', 'methodologies', 'microservices',\n",
              "       'minimize', 'minimizing', 'model', 'models', 'modular', 'mongodb',\n",
              "       'monitoring', 'naseer', 'near', 'ned', 'nov', 'oct', 'of',\n",
              "       'ollama', 'on', 'optimized', 'or', 'oracle', 'organize',\n",
              "       'oriented', 'outputs', 'pakistan', 'pandas', 'passionate',\n",
              "       'performance', 'performing', 'pipeline', 'pipelines', 'platforms',\n",
              "       'portfolio', 'postgresql', 'posting', 'powered', 'prepare',\n",
              "       'present', 'proactive', 'problem', 'process', 'produc',\n",
              "       'production', 'professional', 'project', 'projects', 'prompt',\n",
              "       'prompting', 'python', 'pytorch', 'questions', 'rag', 'ready',\n",
              "       'real', 'recognition', 'redis', 'related', 'repetitive',\n",
              "       'reporting', 'research', 'responses', 'rest', 'results',\n",
              "       'retrieval', 'robotic', 'rpa', 'scalable', 'scraping', 'selenium',\n",
              "       'sept', 'series', 'sign', 'signs', 'simple', 'skilled', 'skills',\n",
              "       'smart', 'social', 'software', 'solving', 'speed', 'stack',\n",
              "       'stored', 'streamline', 'strong', 'support', 'synthetic', 'system',\n",
              "       'systems', 'tasks', 'team', 'teams', 'technical', 'techniques',\n",
              "       'technologies', 'technology', 'testing', 'the', 'time', 'tion',\n",
              "       'to', 'toexcel', 'tools', 'top', 'traffic', 'trained', 'triggers',\n",
              "       'tuned', 'tuning', 'types', 'understanding', 'university', 'used',\n",
              "       'using', 'validation', 'vector', 'vehi', 'vehicles', 'visual',\n",
              "       'voice', 'wake', 'web', 'what', 'willingness', 'with', 'word',\n",
              "       'work', 'worked', 'workflow', 'workflows', 'world', 'year',\n",
              "       'zubair', 'ð—¥ð—²ð—¾ð˜‚ð—¶ð—¿ð—²ð—ºð—²ð—»ð˜ð˜€', 'ð—¥ð—²ð˜€ð—½ð—¼ð—»ð˜€ð—¶ð—¯ð—¶ð—¹ð—¶ð˜ð—¶ð—²ð˜€'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.idf_[293])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8IBHjWZjgbP",
        "outputId": "72155b2e-3714-4e40-ac1e-25c631609aa8"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4054651081081644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectors.shape)\n",
        "print(vectors[0:1].shape)\n",
        "print(vectors[1:2].shape)\n",
        "print(vectors[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0inwzkXBg0V-",
        "outputId": "2035c9ee-fe23-4f30-f2b3-47c27a605983"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 296)\n",
            "(1, 296)\n",
            "(1, 296)\n",
            "(1, 296)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [0,1,2,3]\n",
        "print(a[2])\n",
        "print(a[2:3]) # to preserve array (2D) shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzZ2jZCojwzJ",
        "outputId": "80afec78-1b07-42fa-ca96-b2c2679ddc8f"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "[2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = cosine_similarity(vectors[0:1], vectors[1:2])\n",
        "similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owU0WDRAccFW",
        "outputId": "e9775115-9205-4eb4-dad0-253aece6f338"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12040409]])"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def match_resume_jd(resume_text, jd_text):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([resume_text, jd_text])\n",
        "    similarity = cosine_similarity(vectors[0:1], vectors[1:2])\n",
        "    return similarity[0][0]"
      ],
      "metadata": {
        "id": "a6z7H9Y_SBUi"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_index = match_resume_jd(cv_clean, jd_text)\n",
        "similarity_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXQpHGJs0vZQ",
        "outputId": "9e43db57-f373-4743-f830-f1973b659fc7"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.1204040884053134)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_index = match_resume_jd(cv_2_clean, jd_text)\n",
        "similarity_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs4I6ilU1sKF",
        "outputId": "c34bf3b0-2c46-4548-cac6-8c7bb8934a9d"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.09773058161640913)"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "DTQniNnvSCJC"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "07d3bf21af854aaa9665454add71ff30",
            "7eaa2dcecded4fdb81c1818cea20973f",
            "5328ae9d5f9c4ef59fae508b988e3896",
            "971d1d995d5847518cce70c778c2671f",
            "d8563bc0c46f43948ffb4148923e7c08",
            "7bca17d4c08a47eea0ba992d2643af31",
            "56ecaaebe6af43eeab4869ccc83b40c5",
            "5b7cc34d1abe4e30b30489a853a90b82",
            "f7b7b97c64c04cf2a98d422f356a422c",
            "af6a68450dcc48189df3cab9854c5b2c",
            "d5e8379a6151460c944082a3784b7c88"
          ]
        },
        "id": "iUxdQxRXONCq",
        "outputId": "eb9a2b51-bcd8-433e-af89-70b7650d9d7e"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07d3bf21af854aaa9665454add71ff30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_match(resume, jd):\n",
        "    embeddings = model.encode([resume, jd])\n",
        "    score = util.cos_sim(embeddings[0], embeddings[1])\n",
        "    return score.item()"
      ],
      "metadata": {
        "id": "mHmpEkE2ORgq"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_index = bert_match(cv_2_clean, jd_text)\n",
        "similarity_index"
      ],
      "metadata": {
        "id": "-eaN2CEjSGFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "216374b8-ab92-45a4-b0eb-14e08be1d68c"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5503302216529846"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_index = bert_match(cv_clean, jd_text)\n",
        "similarity_index"
      ],
      "metadata": {
        "id": "esELMwyfnQlr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0bc4eaf-71f5-4132-8c4d-727d31df329d"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6153355836868286"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def combined_score(tfidf_score, bert_score, alpha=0.4):\n",
        "    return alpha * tfidf_score + (1 - alpha) * bert_score"
      ],
      "metadata": {
        "id": "9eExfeADZOTu"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_score = combined_score(match_resume_jd(cv_clean, jd_text), bert_match(cv_clean, jd_text))\n",
        "final_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVNVQCtpQP_k",
        "outputId": "3b760848-d136-40c9-d7e9-cc92216819e6"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.4173629855742225)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vEto4iVLQfdg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}